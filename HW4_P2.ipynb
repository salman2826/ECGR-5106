{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e474ddf3-c6c8-4758-b64a-8d1d1a160584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ahosain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ahosain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "  Training Loss: 4.4347 | Training Accuracy: 0.2548\n",
      "  Validation Loss: 4.1351 | Validation Accuracy: 0.2991\n",
      "Epoch 2/50:\n",
      "  Training Loss: 3.1200 | Training Accuracy: 0.4755\n",
      "  Validation Loss: 3.9528 | Validation Accuracy: 0.2679\n",
      "Epoch 3/50:\n",
      "  Training Loss: 2.4836 | Training Accuracy: 0.5404\n",
      "  Validation Loss: 3.9564 | Validation Accuracy: 0.3125\n",
      "Epoch 4/50:\n",
      "  Training Loss: 2.1514 | Training Accuracy: 0.5518\n",
      "  Validation Loss: 3.9096 | Validation Accuracy: 0.3750\n",
      "Epoch 5/50:\n",
      "  Training Loss: 1.7908 | Training Accuracy: 0.5688\n",
      "  Validation Loss: 3.6038 | Validation Accuracy: 0.4375\n",
      "Epoch 6/50:\n",
      "  Training Loss: 1.5332 | Training Accuracy: 0.6530\n",
      "  Validation Loss: 3.7629 | Validation Accuracy: 0.4152\n",
      "Epoch 7/50:\n",
      "  Training Loss: 1.1853 | Training Accuracy: 0.7190\n",
      "  Validation Loss: 3.5140 | Validation Accuracy: 0.4554\n",
      "Epoch 8/50:\n",
      "  Training Loss: 0.8493 | Training Accuracy: 0.8339\n",
      "  Validation Loss: 3.8240 | Validation Accuracy: 0.4196\n",
      "Epoch 9/50:\n",
      "  Training Loss: 0.5648 | Training Accuracy: 0.9113\n",
      "  Validation Loss: 3.7773 | Validation Accuracy: 0.4688\n",
      "Epoch 10/50:\n",
      "  Training Loss: 0.3210 | Training Accuracy: 0.9727\n",
      "  Validation Loss: 4.1270 | Validation Accuracy: 0.3973\n",
      "Epoch 11/50:\n",
      "  Training Loss: 0.2120 | Training Accuracy: 0.9852\n",
      "  Validation Loss: 4.1168 | Validation Accuracy: 0.4330\n",
      "Epoch 12/50:\n",
      "  Training Loss: 0.1406 | Training Accuracy: 0.9932\n",
      "  Validation Loss: 4.5459 | Validation Accuracy: 0.4062\n",
      "Epoch 13/50:\n",
      "  Training Loss: 0.1143 | Training Accuracy: 0.9920\n",
      "  Validation Loss: 4.5142 | Validation Accuracy: 0.4018\n",
      "Epoch 14/50:\n",
      "  Training Loss: 0.0678 | Training Accuracy: 0.9977\n",
      "  Validation Loss: 4.7487 | Validation Accuracy: 0.3884\n",
      "Epoch 15/50:\n",
      "  Training Loss: 0.0496 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 4.6387 | Validation Accuracy: 0.4018\n",
      "Epoch 16/50:\n",
      "  Training Loss: 0.0386 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 4.7804 | Validation Accuracy: 0.3929\n",
      "Epoch 17/50:\n",
      "  Training Loss: 0.0301 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 4.8712 | Validation Accuracy: 0.3884\n",
      "Epoch 18/50:\n",
      "  Training Loss: 0.0250 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 4.9598 | Validation Accuracy: 0.3884\n",
      "Epoch 19/50:\n",
      "  Training Loss: 0.0208 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 4.9323 | Validation Accuracy: 0.4107\n",
      "Epoch 20/50:\n",
      "  Training Loss: 0.0179 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.0133 | Validation Accuracy: 0.3973\n",
      "Epoch 21/50:\n",
      "  Training Loss: 0.0164 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.0114 | Validation Accuracy: 0.4107\n",
      "Epoch 22/50:\n",
      "  Training Loss: 0.0147 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 4.9836 | Validation Accuracy: 0.4241\n",
      "Epoch 23/50:\n",
      "  Training Loss: 0.0130 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.0822 | Validation Accuracy: 0.4018\n",
      "Epoch 24/50:\n",
      "  Training Loss: 0.0120 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.1212 | Validation Accuracy: 0.4018\n",
      "Epoch 25/50:\n",
      "  Training Loss: 0.0112 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.1196 | Validation Accuracy: 0.4018\n",
      "Epoch 26/50:\n",
      "  Training Loss: 0.0105 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.1714 | Validation Accuracy: 0.4018\n",
      "Epoch 27/50:\n",
      "  Training Loss: 0.0097 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2012 | Validation Accuracy: 0.4018\n",
      "Epoch 28/50:\n",
      "  Training Loss: 0.0091 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2107 | Validation Accuracy: 0.3973\n",
      "Epoch 29/50:\n",
      "  Training Loss: 0.0084 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2051 | Validation Accuracy: 0.3973\n",
      "Epoch 30/50:\n",
      "  Training Loss: 0.0079 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2651 | Validation Accuracy: 0.3973\n",
      "Epoch 31/50:\n",
      "  Training Loss: 0.0075 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2179 | Validation Accuracy: 0.4107\n",
      "Epoch 32/50:\n",
      "  Training Loss: 0.0070 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2306 | Validation Accuracy: 0.4107\n",
      "Epoch 33/50:\n",
      "  Training Loss: 0.0067 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.1828 | Validation Accuracy: 0.4330\n",
      "Epoch 34/50:\n",
      "  Training Loss: 0.0065 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2050 | Validation Accuracy: 0.4330\n",
      "Epoch 35/50:\n",
      "  Training Loss: 0.0060 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2154 | Validation Accuracy: 0.4330\n",
      "Epoch 36/50:\n",
      "  Training Loss: 0.0058 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2286 | Validation Accuracy: 0.4330\n",
      "Epoch 37/50:\n",
      "  Training Loss: 0.0056 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2546 | Validation Accuracy: 0.4330\n",
      "Epoch 38/50:\n",
      "  Training Loss: 0.0053 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3477 | Validation Accuracy: 0.4196\n",
      "Epoch 39/50:\n",
      "  Training Loss: 0.0050 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3633 | Validation Accuracy: 0.4196\n",
      "Epoch 40/50:\n",
      "  Training Loss: 0.0048 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3053 | Validation Accuracy: 0.4330\n",
      "Epoch 41/50:\n",
      "  Training Loss: 0.0046 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3151 | Validation Accuracy: 0.4330\n",
      "Epoch 42/50:\n",
      "  Training Loss: 0.0043 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3316 | Validation Accuracy: 0.4330\n",
      "Epoch 43/50:\n",
      "  Training Loss: 0.0042 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3490 | Validation Accuracy: 0.4330\n",
      "Epoch 44/50:\n",
      "  Training Loss: 0.0040 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2433 | Validation Accuracy: 0.4420\n",
      "Epoch 45/50:\n",
      "  Training Loss: 0.0039 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2502 | Validation Accuracy: 0.4420\n",
      "Epoch 46/50:\n",
      "  Training Loss: 0.0037 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2692 | Validation Accuracy: 0.4420\n",
      "Epoch 47/50:\n",
      "  Training Loss: 0.0036 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.2862 | Validation Accuracy: 0.4420\n",
      "Epoch 48/50:\n",
      "  Training Loss: 0.0035 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3046 | Validation Accuracy: 0.4420\n",
      "Epoch 49/50:\n",
      "  Training Loss: 0.0033 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3078 | Validation Accuracy: 0.4420\n",
      "Epoch 50/50:\n",
      "  Training Loss: 0.0032 | Training Accuracy: 1.0000\n",
      "  Validation Loss: 5.3223 | Validation Accuracy: 0.4420\n",
      "English: I am cold\n",
      "Translated French: sos > nous construisons un château < eos > > < eos > > <\n",
      "English: She speaks French fluently\n",
      "Translated French: parle français couramment français couramment < eos > < eos > < eos > <\n",
      "English: We love music\n",
      "Translated French: aimons la musique la musique < eos > < eos > < eos > <\n",
      "English: He listens to music while jogging\n",
      "Translated French: écoute de la musique en faisant du jogging de la musique en faisant du jogging\n",
      "English: They travel around the world\n",
      "Translated French: ils vont à la salle la table < eos > > < eos > <\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# -----------------------\n",
    "# Data Preparation\n",
    "# -----------------------\n",
    "\n",
    "# Provided dataset: each tuple is (English, French)\n",
    "english_to_french = [\n",
    "    (\"I am cold\", \"J'ai froid\"),\n",
    "    (\"You are tired\", \"Tu es fatigué\"),\n",
    "    (\"He is hungry\", \"Il a faim\"),\n",
    "    (\"She is happy\", \"Elle est heureuse\"),\n",
    "    (\"We are friends\", \"Nous sommes amis\"),\n",
    "    (\"They are students\", \"Ils sont étudiants\"),\n",
    "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
    "    (\"The sun is shining\", \"Le soleil brille\"),\n",
    "    (\"We love music\", \"Nous aimons la musique\"),\n",
    "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
    "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
    "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
    "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
    "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
    "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
    "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
    "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
    "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
    "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
    "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
    "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
    "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
    "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
    "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
    "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
    "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
    "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
    "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
    "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
    "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
    "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
    "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
    "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
    "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
    "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
    "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
    "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
    "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
    "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
    "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
    "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
    "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
    "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
    "    (\"The baby cries\", \"Le bébé pleure\"),\n",
    "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
    "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
    "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
    "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
    "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
    "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
    "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
    "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
    "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
    "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
    "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
    "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
    "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
    "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
    "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
    "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
    "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
    "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
    "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
    "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
    "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
    "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
    "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
    "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
    "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
    "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
    "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
    "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
    "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
    "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
    "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
    "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
    "    (\"He sings in the choir\", \"Il chante dans le chœur\"),\n",
    "    (\"They ride bicycles\", \"Ils font du vélo\"),\n",
    "    (\"The coffee is hot\", \"Le café est chaud\"),\n",
    "    (\"She wears glasses\", \"Elle porte des lunettes\"),\n",
    "    (\"We visit our grandparents\", \"Nous rendons visite à nos grands-parents\"),\n",
    "    (\"He plays the guitar\", \"Il joue de la guitare\"),\n",
    "    (\"They go shopping\", \"Ils font du shopping\"),\n",
    "    (\"The teacher explains the lesson\", \"Le professeur explique la leçon\"),\n",
    "    (\"She takes the train to work\", \"Elle prend le train pour aller au travail\"),\n",
    "    (\"We bake cookies\", \"Nous faisons des biscuits\"),\n",
    "    (\"He washes his hands\", \"Il se lave les mains\"),\n",
    "    (\"They enjoy the sunset\", \"Ils apprécient le coucher du soleil\"),\n",
    "    (\"The river flows calmly\", \"La rivière coule calmement\"),\n",
    "    (\"She feeds the cat\", \"Elle nourrit le chat\"),\n",
    "    (\"We visit the museum\", \"Nous visitons le musée\"),\n",
    "    (\"He fixes his bicycle\", \"Il répare son vélo\"),\n",
    "    (\"They paint the walls\", \"Ils peignent les murs\"),\n",
    "    (\"The baby sleeps peacefully\", \"Le bébé dort paisiblement\"),\n",
    "    (\"She ties her shoelaces\", \"Elle attache ses lacets\"),\n",
    "    (\"We climb the stairs\", \"Nous montons les escaliers\"),\n",
    "    (\"He shaves in the morning\", \"Il se rase le matin\"),\n",
    "    (\"They set the table\", \"Ils mettent la table\"),\n",
    "    (\"The airplane takes off\", \"L'avion décolle\"),\n",
    "    (\"She waters the plants\", \"Elle arrose les plantes\"),\n",
    "    (\"We practice yoga\", \"Nous pratiquons le yoga\"),\n",
    "    (\"He turns off the light\", \"Il éteint la lumière\"),\n",
    "    (\"They play video games\", \"Ils jouent aux jeux vidéo\"),\n",
    "    (\"The soup smells delicious\", \"La soupe sent délicieusement bon\"),\n",
    "    (\"She locks the door\", \"Elle ferme la porte à clé\"),\n",
    "    (\"We enjoy a picnic\", \"Nous profitons d'un pique-nique\"),\n",
    "    (\"He checks his email\", \"Il vérifie ses emails\"),\n",
    "    (\"They go to the gym\", \"Ils vont à la salle de sport\"),\n",
    "    (\"The moon shines brightly\", \"La lune brille intensément\"),\n",
    "    (\"She catches the bus\", \"Elle attrape le bus\"),\n",
    "    (\"We greet our neighbors\", \"Nous saluons nos voisins\"),\n",
    "    (\"He combs his hair\", \"Il se peigne les cheveux\"),\n",
    "    (\"They wave goodbye\", \"Ils font un signe d'adieu\")\n",
    "]\n",
    "\n",
    "# For English-to-French, source is English and target is French.\n",
    "english_sentences = [pair[0] for pair in english_to_french]\n",
    "french_sentences = [pair[1] for pair in english_to_french]\n",
    "# Add special tokens to French target sentences.\n",
    "french_sentences = ['<sos> ' + sent + ' <eos>' for sent in french_sentences]\n",
    "\n",
    "# Tokenization function using NLTK.\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "# Build vocabulary function \n",
    "def build_vocab(sentences):\n",
    "    counter = Counter()\n",
    "    for sent in sentences:\n",
    "        counter.update(tokenize(sent))\n",
    "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "    for word, _ in counter.items():\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# Build vocabularies for English (source) and French (target).\n",
    "eng_vocab = build_vocab(english_sentences)\n",
    "fr_vocab = build_vocab(french_sentences)\n",
    "eng_pad_idx = eng_vocab['<pad>']\n",
    "fr_pad_idx = fr_vocab['<pad>']\n",
    "\n",
    "# Inverse mapping for target decoding (French).\n",
    "inv_fr_vocab = {i: w for w, i in fr_vocab.items()}\n",
    "\n",
    "# Numericalize sentences.\n",
    "def numericalize(sentences, vocab):\n",
    "    return [[vocab.get(word, vocab['<unk>']) for word in tokenize(sent)] for sent in sentences]\n",
    "\n",
    "eng_sequences = numericalize(english_sentences, eng_vocab)\n",
    "fr_sequences = numericalize(french_sentences, fr_vocab)\n",
    "\n",
    "# -----------------------\n",
    "# Create Dataset and DataLoader\n",
    "# -----------------------\n",
    "\n",
    "def pad_seq(seq, max_len, pad_idx):\n",
    "    return seq + [pad_idx] * (max_len - len(seq))\n",
    "\n",
    "max_eng_len = max(len(seq) for seq in eng_sequences)\n",
    "max_fr_len = max(len(seq) for seq in fr_sequences)\n",
    "\n",
    "eng_sequences = [pad_seq(seq, max_eng_len, eng_pad_idx) for seq in eng_sequences]\n",
    "fr_sequences = [pad_seq(seq, max_fr_len, fr_pad_idx) for seq in fr_sequences]\n",
    "\n",
    "data = list(zip(eng_sequences, fr_sequences))\n",
    "random.shuffle(data)\n",
    "split_idx = int(0.8 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "val_data = data[split_idx:]\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # list of (source, target)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.data[idx]\n",
    "        return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "train_dataset = TranslationDataset(train_data)\n",
    "val_dataset = TranslationDataset(val_data)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# -----------------------\n",
    "# Model Definitions with Attention\n",
    "# -----------------------\n",
    "\n",
    "# Encoder: processes English input.\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)  # [batch, src_len, emb_dim]\n",
    "        outputs, hidden = self.gru(embedded)  # outputs: [batch, src_len, hid_dim]\n",
    "        return outputs, hidden.squeeze(0)      # hidden: [batch, hid_dim]\n",
    "\n",
    "# Attention.\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: [batch, hid_dim]\n",
    "        # encoder_outputs: [batch, src_len, hid_dim]\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        # Repeat decoder hidden state src_len times.\n",
    "        decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)  # [batch, src_len, hid_dim]\n",
    "        energy = torch.tanh(self.attn(torch.cat((decoder_hidden, encoder_outputs), dim=2)))  # [batch, src_len, hid_dim]\n",
    "        attention = self.v(energy).squeeze(2)  # [batch, src_len]\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "# Decoder with Attention.\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, pad_idx, attention):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
    "        # GRU input will be the concatenation of embedding and context vector.\n",
    "        self.gru = nn.GRU(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
    "        # Final output combines GRU output, context vector, and embedding.\n",
    "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input: [batch] -> [batch, 1]\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))  # [batch, 1, emb_dim]\n",
    "        # Compute attention weights.\n",
    "        a = self.attention(hidden, encoder_outputs)  # [batch, src_len]\n",
    "        a = a.unsqueeze(1)  # [batch, 1, src_len]\n",
    "        # Compute weighted sum of encoder outputs.\n",
    "        context = torch.bmm(a, encoder_outputs)  # [batch, 1, hid_dim]\n",
    "        # Concatenate embedded and context.\n",
    "        gru_input = torch.cat((embedded, context), dim=2)  # [batch, 1, emb_dim+hid_dim]\n",
    "        output, hidden = self.gru(gru_input, hidden.unsqueeze(0))\n",
    "        hidden = hidden.squeeze(0)       # [batch, hid_dim]\n",
    "        output = output.squeeze(1)       # [batch, hid_dim]\n",
    "        context = context.squeeze(1)     # [batch, hid_dim]\n",
    "        embedded = embedded.squeeze(1)   # [batch, emb_dim]\n",
    "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=1))  # [batch, output_dim]\n",
    "        return prediction, hidden\n",
    "\n",
    "# Seq2Seq model with Attention.\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        tgt_vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input = tgt[:, 0]  # first token (<sos>)\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "# Hyperparameters and device.\n",
    "INPUT_DIM = len(eng_vocab)\n",
    "OUTPUT_DIM = len(fr_vocab)\n",
    "EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "attn = Attention(HID_DIM)\n",
    "encoder = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, eng_pad_idx)\n",
    "decoder = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, fr_pad_idx, attn)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "# -----------------------\n",
    "# Training Setup\n",
    "# -----------------------\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=fr_pad_idx)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt, teacher_forcing_ratio=0.5)\n",
    "        # output: [batch, tgt_len, output_dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        preds = output.argmax(1)\n",
    "        non_pad = (tgt != fr_pad_idx)\n",
    "        correct = (preds == tgt) & non_pad\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_total += non_pad.sum().item()\n",
    "    return epoch_loss / len(dataloader), epoch_correct / epoch_total\n",
    "\n",
    "def evaluate_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(DEVICE)\n",
    "            tgt = tgt.to(DEVICE)\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            tgt = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "            preds = output.argmax(1)\n",
    "            non_pad = (tgt != fr_pad_idx)\n",
    "            correct = (preds == tgt) & non_pad\n",
    "            epoch_correct += correct.sum().item()\n",
    "            epoch_total += non_pad.sum().item()\n",
    "    return epoch_loss / len(dataloader), epoch_correct / epoch_total\n",
    "\n",
    "N_EPOCHS = 50\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate_epoch(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch}/{N_EPOCHS}:\")\n",
    "    print(f\"  Training Loss: {train_loss:.4f} | Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "# Inference / Qualitative Validation\n",
    "# -----------------------\n",
    "\n",
    "def translate_sentence(model, sentence, eng_vocab, fr_vocab, inv_fr_vocab, max_eng_len, max_fr_len):\n",
    "    model.eval()\n",
    "    tokens = tokenize(sentence)\n",
    "    numericalized = [eng_vocab.get(tok, eng_vocab['<unk>']) for tok in tokens]\n",
    "    numericalized = numericalized + [eng_pad_idx] * (max_eng_len - len(numericalized))\n",
    "    src_tensor = torch.tensor(numericalized, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "    encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "    input_token = torch.tensor([fr_vocab['<sos>']], dtype=torch.long).to(DEVICE)\n",
    "    decoded_sentence = []\n",
    "    for t in range(max_fr_len):\n",
    "        output, hidden = model.decoder(input_token, hidden, encoder_outputs)\n",
    "        top1 = output.argmax(1).item()\n",
    "        if top1 == fr_vocab['<eos>']:\n",
    "            break\n",
    "        decoded_sentence.append(inv_fr_vocab.get(top1, '<unk>'))\n",
    "        input_token = torch.tensor([top1], dtype=torch.long).to(DEVICE)\n",
    "    return ' '.join(decoded_sentence)\n",
    "\n",
    "# Test translation on some English sentences.\n",
    "test_sentences = [\n",
    "    \"I am cold\",\n",
    "    \"She speaks French fluently\",\n",
    "    \"We love music\",\n",
    "    \"He listens to music while jogging\",\n",
    "    \"They travel around the world\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translation = translate_sentence(model, sentence, eng_vocab, fr_vocab, inv_fr_vocab, max_eng_len, max_fr_len)\n",
    "    print(f\"English: {sentence}\")\n",
    "    print(f\"Translated French: {translation}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b1b22-55f0-4836-a8a7-5fc88de305b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
